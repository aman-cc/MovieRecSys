{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/netflix-prize-data/qualifying.txt\n/kaggle/input/netflix-prize-data/probe.txt\n/kaggle/input/netflix-prize-data/movie_titles.csv\n/kaggle/input/netflix-prize-data/combined_data_3.txt\n/kaggle/input/netflix-prize-data/combined_data_2.txt\n/kaggle/input/netflix-prize-data/README\n/kaggle/input/netflix-prize-data/combined_data_1.txt\n/kaggle/input/netflix-prize-data/combined_data_4.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import math\nimport re\nfrom scipy.sparse import csr_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom surprise import Reader, Dataset, SVD, evaluate\nsns.set_style(\"ticks\")","execution_count":2,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'evaluate' from 'surprise' (/opt/conda/lib/python3.7/site-packages/surprise/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ab38d6d693d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ticks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'evaluate' from 'surprise' (/opt/conda/lib/python3.7/site-packages/surprise/__init__.py)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Skip date\ndf1 = pd.read_csv('/kaggle/input/netflix-prize-data/combined_data_1.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n\ndf1['Rating'] = df1['Rating'].astype(float)\n\nprint('Dataset 1 shape: {}'.format(df1.shape))\nprint('-Dataset examples-')\nprint(df1.iloc[::5000000, :])","execution_count":4,"outputs":[{"output_type":"stream","text":"Dataset 1 shape: (24058263, 2)\n-Dataset examples-\n          Cust_Id  Rating\n0              1:     NaN\n5000000   2560324     4.0\n10000000  2271935     2.0\n15000000  1921803     2.0\n20000000  1933327     3.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df1\n\n\ndf.index = np.arange(0,len(df))\nprint('Full dataset shape: {}'.format(df.shape))\nprint('-Dataset examples-')\nprint(df.iloc[::5000000, :])","execution_count":8,"outputs":[{"output_type":"stream","text":"Full dataset shape: (24058263, 2)\n-Dataset examples-\n          Cust_Id  Rating\n0              1:     NaN\n5000000   2560324     4.0\n10000000  2271935     2.0\n15000000  1921803     2.0\n20000000  1933327     3.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nan = pd.DataFrame(pd.isnull(df.Rating))\ndf_nan = df_nan[df_nan['Rating'] == True]\ndf_nan = df_nan.reset_index()\n\nmovie_np = []\nmovie_id = 1\n\nfor i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n    # numpy approach\n    temp = np.full((1,i-j-1), movie_id)\n    movie_np = np.append(movie_np, temp)\n    movie_id += 1\n\n# Account for last record and corresponding length\n# numpy approach\nlast_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\nmovie_np = np.append(movie_np, last_record)\n\nprint('Movie numpy: {}'.format(movie_np))\nprint('Length: {}'.format(len(movie_np)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[pd.notnull(df['Rating'])]\n\ndf['Movie_Id'] = movie_np.astype(int)\ndf['Cust_Id'] = df['Cust_Id'].astype(int)\nprint('-Dataset examples-')\nprint(df.iloc[::5000000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = ['count','mean']\n\ndf_movie_summary = df.groupby('Movie_Id')['Rating'].agg(f)\ndf_movie_summary.index = df_movie_summary.index.map(int)\nmovie_benchmark = round(df_movie_summary['count'].quantile(0.8),0)\ndrop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n\nprint('Movie minimum times of review: {}'.format(movie_benchmark))\n\ndf_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\ndf_cust_summary.index = df_cust_summary.index.map(int)\ncust_benchmark = round(df_cust_summary['count'].quantile(0.8),0)\ndrop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n\nprint('Customer minimum times of review: {}'.format(cust_benchmark))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Original Shape: {}'.format(df.shape))\ndf = df[~df['Movie_Id'].isin(drop_movie_list)]\ndf = df[~df['Cust_Id'].isin(drop_cust_list)]\nprint('After Trim Shape: {}'.format(df.shape))\nprint('-Data Examples-')\nprint(df.iloc[::5000000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p = pd.pivot_table(df,values='Rating',index='Cust_Id',columns='Movie_Id')\n\nprint(df_p.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_title = pd.read_csv('../input/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\ndf_title.set_index('Movie_Id', inplace = True)\nprint (df_title.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader()\n\n# get just top 100K rows for faster run time\ndata = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']][:100000], reader)\ndata.split(n_folds=3)\n\nsvd = SVD()\nevaluate(svd, data, measures=['RMSE', 'MAE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader()\n\n# get just top 100K rows for faster run time\ndata = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']][:100000], reader)\ndata.split(n_folds=3)\n\nsvd = SVD()\nevaluate(svd, data, measures=['RMSE', 'MAE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_785314 = df_title.copy()\nuser_785314 = user_785314.reset_index()\nuser_785314 = user_785314[~user_785314['Movie_Id'].isin(drop_movie_list)]\n\n# getting full dataset\ndata = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n\ntrainset = data.build_full_trainset()\nsvd.train(trainset)\n\nuser_785314['Estimate_Score'] = user_785314['Movie_Id'].apply(lambda x: svd.predict(785314, x).est)\n\nuser_785314 = user_785314.drop('Movie_Id', axis = 1)\n\nuser_785314 = user_785314.sort_values('Estimate_Score', ascending=False)\nprint(user_785314.head(10))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}